## TIỀN XỬ LÝ DỮ LIỆU
### CÁC KHÁI NIỆM VÀ TỔNG QUÁT VỀ DỮ LIỆU
- **Dữ liệu bị khuyết**:
  - MNAR: Dữ liệu khuyết không phải ngẫu nhiên nếu có 1 cơ chế hoặc 1 lý do nào đó khiến các giá trị bị khuyết đưa vào tập dữ liệu.
  - MCAR: Dữ liệu khuyết hoàn toàn là ngẫu nghiên, với xác suất thiếu là như nhau.
  - MCR: Dữ liệu khuyết ngẫu nhiên, Xác suất của một quan sát bị thiếu phụ thuộc vào thông tin sẵn có, nó độc lập với các biến khác trong tập dữ liệu.
-**Nhãn hiểm (rare label)**: là những giá trị được chọn trong một nhóm các hạng mục (nhãn). Các nhãn thường xuất hiện trong tập dữ liệu có tần suất khác nhau. Nhãn hiểm có thể thêm nhiều thông tin hoặc không thêm thông tin. 
  - Các nhãn hiểm trong hạng mục có xu hướng gây ra overfitting, đặc biệt trong các thuật toán cây
  - Nhãn hiểm có thể xuất hiện trong  trainning set mà không xuất hiện trong test set gây ra overfitting cho tập training
  - Nhãn hiểm có thể xuất hiện trong tập test mà không xuất hiện trong tập training, như vậy, model sẽ không biết đánh giá nó như thế nào
- **Giả định tuyến tính**:
Một số giả định của mô hình hồi quy tuyến tính:
  - Độ tuyến tính (Linearity): Các giá trị trung bình của biến kết quả với mỗi gia số yếu tố dự đoán nằm dọc theo một đường thắng hay có một mối quan hệ tuyến tính giữa các yếu tố dự báo và mục tiêu
  - Không có đa cộng tuyến hoàn hảo: Không tồn tại mối quan hệ tuyến tính tuyệt hảo giữa 2 biến hoặc nhiều yếu tố dự báo
  - Lỗi phân phối chuẩn: Các phần dư được phân phối chuẩn ngẫu nhiên với giá trị trung bình bằng 0
  - Phương sai không đổi: Ở mức độ của biến dự báo, phương sai của các phân tử không đổi
- **Ngoại lai (Outlier)**: là điểm dữ liệu khác biệt đáng kể so với dữ liệu còn lại." Outlier là quan sát sai lệch rất nhiêu so với quan sát khác, làm dấy lên nghi ngờ rằng nó được tạo ra bằng 1 cơ chế khác. Tùy vào những hoàn cảnh ta loại bỏ outlier hoặc không, có một số mô hình ảnh hưởng outlier khá nhiều. 
  - Nếu biến là phân phối chuẩn thì giá trị nằm ngoài giá trị trung bình cộng/trừ 3 lần độ lệch chuẩn là outlier
    - outlier = mean +/- 3 * std
  - Nếu biến phân phối lệch thì phương pháp tính IQR
    - IQR = Q3 - Q1
  - Outlier sẽ nằm ngoài upper boundary và lower boundary như sau:
    - Upper boundary = Q3 + IQR*1.5
    - Lower boundary = Q1 - IQR*1.5
### XỬ LÝ DỮ LIỆU THIẾU (Missing Data)
- **Xóa giá trị bị thiếu đi**
  - Nếu dữ liệu khuyết hoàn toàn ngẫu nhiên(MCAR)
  - Dữ liệu bị thiếu không quá 5% hoặc ít hơn 5%
    - Ưu điểm:
      - Dễ thực hiện, nhanh chóng
      - Duy trì được phân phối biến( Nếu dữ liệu MCAR thì phân phối sau khi rút gọn phải khớp với phân phối ban đầu)
    - Nhược điểm:
      - Nó có thể là phần lớn của dữ liệu phần đầu
      - Các quan sát bị loại trừ có thể cung cấp thông tin quan trọng
      - Mô hình trong sản xuất, mô hình sẽ không biết các xử lý dữ liệu bị khuyết
- **Gán giá trị trung bình - trung vị**
  - Nếu dữ liệu bị khuyết hoàn toàn ngẫu nhiên MCAR
  - Các quan sát bị khuyết có thể trong giống như phần lớn các quan sát trong biến 
  - Nếu dữ liệu là phân phối chuẩn thì mean và median sẽ xấp xỉ nhau, do đó thay giá trị nào cũng được
  - Nếu dữ liệu có phân bị lệch thì ta sẽ gán median 
  - Dữ liệu bị khuyết không quá 5%, trong thực tế, gán mean/median rất được sử dụng, ngay cả khi dữ liệu ko phải MCAR và khuyết nhiều giá trị
    - Ưu điểm:
      - Dễ thực hiện, nhanh chóng
    - Nhược điểm
      - Làm thay đổi phân phối biến ban đầu
      - Làm thay đổi phương sai ban đầu
      - Làm thay đổi ma trận hiệp phương sai so với các biến còn lại trong tập dữ liệu
- **Gán giá trị bất kỳ**
  - Nếu dữ liệu không khuyết ngẫu nhiên MNAR
    - Ưu điểm:
      - Dễ thực hiện,nhanh chóng
      - Nắm bắt được tầm quan trọng của của khuyết nếu có 
    - Nhược điểm:
      - Thay đổi phương sai và dạng phân phối ban đầu
      - Nếu giá trị nằm ở cuối phân phối, nó che dấu hoặc tạo ra các giá trị outlier
      - Cần cận thận chọn để không phải một giá trị bất kỳ nào quá giống mean/median
      - Thay đổi ma trận hiệp phương sai so với các biến còn lại   
- **Gán giá trị ở cuối phân phối**
  - Các dữ liệu không khuyết ngẫu nhiên MNAR
    - Ưu điểm:
      - Dễ thực hiện và nhanh chóng
      - Nắm bắt được tầm quan trọng giá trị bị khuyết 
    - Nhược điểm:
      - Làm thay đổi dạng phân phối ban đầu và thay đổi phương sai , ma trận phương sai
      - Làm che dấu các điểm outlier 
- **Gán giá trị hạng mục hay xuất hiện**
  - Dữ liệu khuyết hoàn toàn ngẫu nhiên MNAR
  - Các giá trị bị khuyết hầu hết trong giống với mode
  - Dữ liệu không quá 5%
    - Ưu điểm:
      - Dễ thực hiện, nhanh chóng
    - Nhược điểm:
      - Làm biến dạng mối quan hệ nhãn thường xuất hiện với biến khác
      - Có gây overfit của nhãn thường xuất hiện nếu nhiều giá trị Na    
- **Gán giá trị bị thiếu với một hạng mục mới**
  - Phù hợp với nhiều giá trị bị khuyết 
    - Ưu điểm:
      - Dễ dàng thực hiện, nhanh chóng
      - Không có giả định về dữ liệu
    - Nhược điểm:
      - Nếu số lượng Na quá nhỏ và bổ sung thêm hạng mục có thể gây overfit  
- **Gán mẫu ngẫu nhiên**
  - Gán mẫu ngẫu nhiên gồm việc 1 quan sát ngẫu nhiên từ vùng các quan sát có sẵn của biến và sử dụng giá trị được trích xuất ngẫu nhiên đó để điền NA. Trong gán mẫu ngẫu nhiên, càng có nhiều giá trị Na trong biến thì càng lấy nhiều quan sát ngẫu nhiên
  - Giả định dữ liệu khuyết hoàn toàn ngẫu nhiên MCAR
    - Ưu điểm:
      - Dễ thực hiện,nhanh chóng
      - Bảo toàn phương sai 
    - Nhược điểm: 
      - Tính ngẫu nhiên
      - Mối quan hệ của các biến gán với biến khác sẽ bị ảnh hưởng
      - Cần nhiều bộ nhớ triển khai, vì chúng ta cần lưu trữ tập huấn luyện ban đầu để trích xuất các giá trị thay Na 
   - Dữ liệu bị khuyết không quá 5%
   - Phù hợp cho mô hình tuyến tính vì nó không thay đổi phân phối ban đầu
- **Gán chỉ số khuyết dữ liệu**
  -  Dữ liệu không bị khuyết ngẫu nhiên, chúng ta có thể thay thể các giá trị quan sát mean,median,mode và gắn thêm cờ các giá trị bị khuyết đó, cờ sẽ là chỉ số nhị phân 0/1
  -  Cặp kết hợp: Mean/median + chỉ số , mode + chỉ số, mẫu ngẫu nhiên + chỉ số
  -  Dữ liệu bị khuyết ko có tính dự đoán
      - Ưu điểm:
        -  Dễ thực hiện
        -  Nắm bắt được tầm quan trọng của khuyết
      - Nhược điểm:
        - Mở rộng không gian đặc trưng
        - Biến ban đầu vẫn cần được gán để loại bỏ Na 
- **Gán theo KNN**
  - Các giá trị bị khuyết được ước tính như giá trị trung bình từ K neighbour (lân cận) gần nhất
  - Thư viện: Sklearn.impute.KNNImputer

### MÃ HÓA DỮ LIỆU (Encoding Data)
- **Mã hóa one-hot**
  - Mã hóa one-hot là mã hóa từng hạng mục với biến boolean khác nhận các giá trị 0 hoặc 1
  - Mã hóa K-1: tính đến việc sử dụng ít hơn 1 thứ nguyên nhưng vẫn biểu diễn được toàn bộ thông tin và tránh đưa vào thông tin dư thừa
  - Mã hóa K: Khi xây dựng thuật toán cây, Khi lựa chọn đặc trưng bởi các thuật toán đệ quy, Khi muốn xác định mức quan trọng từng hạng mục riêng lẻ
    - Ưu điểm:
      - Dễ thực hiện
      - Không đưa ra giả định về các hạng mục hoặc phân phối của biến hạng mục
      - Giữa được thông tin của biến hạng mục
      - Thích hợp mô hình tuyến tính 
    - Nhược điểm: 
      - Mở rộng không gian đặc trưng
      - Nhiều biến giả có thể giống nhau, đưa ra thông tin dư thừa
      - Không thêm được thông tin sau khi đã mã hóa
   - Thư viện hỗ trợ: pandas,sklearn,feature-engine 
- **Mã hóa hạng mục thường xuất hiện (OHE)**
  - Khi cardinality cao và nhãn hiểm có thể chỉ xuất hiện trong tập training, gây ra overfit hoặc chỉ trong tập test và gặp rắc rối và tính toán khi không gian đặc trưng quá lớn
  - Lựa chọn ngưỡng những hạng mục hay xuất hiện và mã hóa one-hot
    - Ưu điểm:
      - Dễ thực hiện, nhanh chóng
      - Không mở rộng quá nhiều không gian đặc trưng
      - Thích hợp mô hình tuyến tính
    - Nhược điểm:
      - Dễ mất thông tin khi bỏ qua nhãn đó
      - Không thêm được thông tin sau khi đã mã hóa
  - Thư viện hỗ trợ: Pandas, Sklearn,Feature-engine

- **Mã hóa số nguyên**
  - Thay thế các hạng mục thay thế bằng chữ số 0-n
    - Ưu điểm:
      - Dễ dàng triển khai
      - Không mở rộng không gian đặc trưng 
    - Nhược điểm: 
      - Không thu thấp được thông tin về nhãn hạng mục
      - Không thích hợp mô hình tuyến tính
  - Thư viện hỗ trợ: Pandas, Sklearn,Feature-engine

- **Mã hóa có mục tiêu**
  - Tính đơn điệu
    - Khi một giá trị của 1 biến tăng lên thì giá trị biến kia cũng vậy
    - Khi 1 biến tăng, biến kia lại giảm
  - Ưu điểm
    - Nắm bắt thông tin trong hạng mục
    - Tạo mối quan hệ đơn điệu của biến và mục tiêu đề phù hợp mô hình tuyến tính
    - Không mở rộng không gian đặc trưng
  - Nhược điểm:
    - Dễ dẫn tới overfitting
    - Khó kiểm định chéo với các thư viện hiện tại
  - Thư viện hỗ trợ: Pandas, Featue-engine 
- **Mã hóa đếm_tần số**
  -  Chúng ta thay thế các hạng mục bằng số lượng quan sát hiện thị hạng mục trong tập dữ liệu, chúng ta cũng có thể thay thế hạn mục bằng tần số hoặc tỷ lệ phần trăm
  -  Ưu điểm
     - Đơn giản
     - Không mở rộng không gian đặc trưng   
  -  Nhược điểm 
     - Nếu 2 hạng mục khác nhau có cùng tần số xuất hiện trong tập dữ liệu, tức là chúng có số lượng quan sát giống nhau thì sẽ được thay thể bằng cùng 1 số: có thể mất thông tin có giá trị  
  - Thư viện hỗ trợ: Pandas,Featue-engine

### CHUẨN HÓA DỮ LIỆU (Scale Data)
- **Co giãn Min-Max(MinMaxScaling)**
- **Chuẩn tắc hóa(Standardisation)**
- **Chuẩn hóa trung bình(Mean normalisation)**
- **Co giãn về giá trị lớn nhất tuyệt đổi(MaxAbsScaling)**
- **Co giãn về trung vị và phân vị (RobustScaling)**
- **Chuẩn hóa độ dài vector đơn vị**
### LỰA CHỌN ĐẶC TRƯNG (Select feature)
